{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b24c3ee-aff9-4f86-bde7-51ac0f099c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from shutil import copyfile, move\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206009e2-cff4-43ed-9423-764baa695dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.9/site-packages (1.5.12)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.9/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.9/site-packages (from kaggle) (6.1.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.9/site-packages (from kaggle) (1.26.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->kaggle) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->kaggle) (3.3)\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jovyan/.kaggle/kaggle.json'\n",
      "rtsd-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,16 CPUs Intel(R) Xeon(R) W-2145 CPU @ 3.70GHz (50654),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Sca        1 file, 18405377368 bytes (18 GiB)\n",
      "\n",
      "Extracting archive: rtsd-dataset.zip\n",
      "  2% 4096 Op            --\n",
      "Path = rtsd-dataset.zip\n",
      "Type = zip\n",
      "Physical Size = 18405377368\n",
      "64-bit = +\n",
      "\n",
      "    \n",
      "Would you like to replace the existing file:\n",
      "  Path:     ./label_map.json\n",
      "  Size:     1951 bytes (2 KiB)\n",
      "  Modified: 2022-04-03 07:16:20\n",
      "with the file from archive:\n",
      "  Path:     label_map.json\n",
      "  Size:     1951 bytes (2 KiB)\n",
      "  Modified: 2022-04-03 07:16:20\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? ^C\n",
      "(Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!kaggle datasets download -d watchman/rtsd-dataset\n",
    "!7z x rtsd-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b6647-9ce8-4088-8cc2-ab66d7e153f5",
   "metadata": {},
   "source": [
    "# COCO TO YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b54a423-dda0-460b-ae09-f141028ec6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'JSON2YOLO' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/JSON2YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c0ee83-94ee-4b5d-96e7-db332e2ed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./JSON2YOLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f629c4-219a-45b6-8ec5-bed14abbc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JSON2YOLO.general_json2yolo import convert_coco_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06c3463-2bb5-489c-bec0-6b1ea2c06237",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_anno.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/shutil.py:814\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_anno.json' -> 'train_annotation/train_anno.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_anno.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_annotation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_anno.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m move(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_anno.json\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_anno.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/shutil.py:834\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    832\u001b[0m         rmtree(src)\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 834\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/shutil.py:443\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    442\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/shutil.py:265\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc, \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    267\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    268\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_anno.json'"
     ]
    }
   ],
   "source": [
    "test_path = 'test_annotation'\n",
    "train_path = 'train_annotation'\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "move('train_anno.json', os.path.join(train_path, 'train_anno.json'))\n",
    "move('val_anno.json', os.path.join(test_path, 'val_anno.json'))\n",
    "\n",
    "for folder in ['labels', 'images']:\n",
    "    for path in [test_path, train_path]:\n",
    "        os.makedirs(os.path.join(path, folder), exist_ok=True)\n",
    "        \n",
    "convert_coco_json(train_path)\n",
    "for file in tqdm(os.listdir(os.path.join('new_dir/labels/train_anno'))):\n",
    "    move(os.path.join('new_dir/labels/train_anno', file), os.path.join(train_path, 'labels', file))\n",
    "    \n",
    "convert_coco_json('./test_annotation/')\n",
    "for file in tqdm(os.listdir(os.path.join('new_dir/labels/val_anno'))):\n",
    "    move(os.path.join('new_dir/labels/val_anno', file), os.path.join(test_path, 'labels', file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad25a7-e5cf-4241-9670-0551bdab1b07",
   "metadata": {},
   "source": [
    "# distribute images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b86ddb3b-489c-4600-ba4c-05f4424e7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = os.listdir(os.path.join(test_path, 'labels'))\n",
    "train_labels = os.listdir(os.path.join(train_path, 'labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0cca5c3-f38b-4f3c-b5fb-ca9a7299f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = set(map(lambda x: x.split('.')[0], test_labels))\n",
    "train_labels = set(map(lambda x: x.split('.')[0], train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "793a5a86-5205-42cd-8666-449ac7c515a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = 'rtsd-frames/rtsd-frames'\n",
    "for file in os.listdir(images):\n",
    "    name = file.split('.')[0]\n",
    "    if name in train_labels:\n",
    "        move(os.path.join(images, file), os.path.join(train_path,'images', file))\n",
    "    if name in test_labels:\n",
    "        move(os.path.join(images, file), os.path.join(test_path,'images', file))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba206c-78f8-4dee-85be-ac8862a84169",
   "metadata": {},
   "source": [
    "# labels in yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f627690-ac5a-41ea-af38-12188b404536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/hack/label_map.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c84d1b7-fac7-4190-96b8-0a1c2b1cd2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_1',\n",
       " '1_23',\n",
       " '1_17',\n",
       " '3_24',\n",
       " '8_2_1',\n",
       " '5_20',\n",
       " '5_19_1',\n",
       " '5_16',\n",
       " '3_25',\n",
       " '6_16',\n",
       " '7_15',\n",
       " '2_2',\n",
       " '2_4',\n",
       " '8_13_1',\n",
       " '4_2_1',\n",
       " '1_20_3',\n",
       " '1_25',\n",
       " '3_4',\n",
       " '8_3_2',\n",
       " '3_4_1',\n",
       " '4_1_6',\n",
       " '4_2_3',\n",
       " '4_1_1',\n",
       " '1_33',\n",
       " '5_15_5',\n",
       " '3_27',\n",
       " '1_15',\n",
       " '4_1_2_1',\n",
       " '6_3_1',\n",
       " '8_1_1',\n",
       " '6_7',\n",
       " '5_15_3',\n",
       " '7_3',\n",
       " '1_19',\n",
       " '6_4',\n",
       " '8_1_4',\n",
       " '8_8',\n",
       " '1_16',\n",
       " '1_11_1',\n",
       " '6_6',\n",
       " '5_15_1',\n",
       " '7_2',\n",
       " '5_15_2',\n",
       " '7_12',\n",
       " '3_18',\n",
       " '5_6',\n",
       " '5_5',\n",
       " '7_4',\n",
       " '4_1_2',\n",
       " '8_2_2',\n",
       " '7_11',\n",
       " '1_22',\n",
       " '1_27',\n",
       " '2_3_2',\n",
       " '5_15_2_2',\n",
       " '1_8',\n",
       " '3_13',\n",
       " '2_3',\n",
       " '8_3_3',\n",
       " '2_3_3',\n",
       " '7_7',\n",
       " '1_11',\n",
       " '8_13',\n",
       " '1_12_2',\n",
       " '1_20',\n",
       " '1_12',\n",
       " '3_32',\n",
       " '2_5',\n",
       " '3_1',\n",
       " '4_8_2',\n",
       " '3_20',\n",
       " '3_2',\n",
       " '2_3_6',\n",
       " '5_22',\n",
       " '5_18',\n",
       " '2_3_5',\n",
       " '7_5',\n",
       " '8_4_1',\n",
       " '3_14',\n",
       " '1_2',\n",
       " '1_20_2',\n",
       " '4_1_4',\n",
       " '7_6',\n",
       " '8_1_3',\n",
       " '8_3_1',\n",
       " '4_3',\n",
       " '4_1_5',\n",
       " '8_2_3',\n",
       " '8_2_4',\n",
       " '1_31',\n",
       " '3_10',\n",
       " '4_2_2',\n",
       " '7_1',\n",
       " '3_28',\n",
       " '4_1_3',\n",
       " '5_4',\n",
       " '5_3',\n",
       " '6_8_2',\n",
       " '3_31',\n",
       " '6_2',\n",
       " '1_21',\n",
       " '3_21',\n",
       " '1_13',\n",
       " '1_14',\n",
       " '2_3_4',\n",
       " '4_8_3',\n",
       " '6_15_2',\n",
       " '2_6',\n",
       " '3_18_2',\n",
       " '4_1_2_2',\n",
       " '1_7',\n",
       " '3_19',\n",
       " '1_18',\n",
       " '2_7',\n",
       " '8_5_4',\n",
       " '5_15_7',\n",
       " '5_14',\n",
       " '5_21',\n",
       " '1_1',\n",
       " '6_15_1',\n",
       " '8_6_4',\n",
       " '8_15',\n",
       " '4_5',\n",
       " '3_11',\n",
       " '8_18',\n",
       " '8_4_4',\n",
       " '3_30',\n",
       " '5_7_1',\n",
       " '5_7_2',\n",
       " '1_5',\n",
       " '3_29',\n",
       " '6_15_3',\n",
       " '5_12',\n",
       " '3_16',\n",
       " '1_30',\n",
       " '5_11',\n",
       " '1_6',\n",
       " '8_6_2',\n",
       " '6_8_3',\n",
       " '3_12',\n",
       " '3_33',\n",
       " '8_4_3',\n",
       " '5_8',\n",
       " '8_14',\n",
       " '8_17',\n",
       " '3_6',\n",
       " '1_26',\n",
       " '8_5_2',\n",
       " '6_8_1',\n",
       " '5_17',\n",
       " '1_10',\n",
       " '8_16',\n",
       " '7_18',\n",
       " '7_14',\n",
       " '8_23']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb7ea9-94bb-4213-aa21-8814887a8daa",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733275f-006e-4f47-9f03-4db84aa71373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!sudo apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbafd4b8-bbf7-4876-b634-2725dbbe0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvictor30608\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dde20df4-83ff-44ef-9ed3-f5489e520183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 14375, done.\u001b[K\n",
      "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
      "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
      "remote: Total 14375 (delta 113), reused 124 (delta 69), pack-reused 14194\u001b[K\n",
      "Receiving objects: 100% (14375/14375), 13.43 MiB | 10.74 MiB/s, done.\n",
      "Resolving deltas: 100% (9923/9923), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8db15506-77fe-4c73-b5f3-38070d51cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"yolov5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd34c2a-f791-485e-904e-75db1a56197e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b500912b-21d2-4177-9767-11273e5ed841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvictor30608\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=/home/jovyan/hack/trafic_signs.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=-1, imgsz=1280, rect=False, resume=True, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=hackaton_trafic_signs, name=yolov5m6, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 57, done.\u001b[K\n",
      "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 57 (delta 38), reused 48 (delta 30), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (57/57), 20.48 KiB | 998.00 KiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   d5791e87..8b47a246  exp8       -> origin/exp8\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "YOLOv5 üöÄ v6.2-195-gdf80e7c7 Python-3.9.7 torch-1.12.0+cu113 CUDA:0 (NVIDIA RTX A5000, 24256MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hackaton_trafic_signs', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jovyan/yolov5/wandb/run-20221015_191904-1m5g53d8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33myolov5m6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/victor30608/hackaton_trafic_signs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/victor30608/hackaton_trafic_signs/runs/1m5g53d8\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n",
      "  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n",
      "  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n",
      " 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      " 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n",
      " 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n",
      " 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n",
      " 33  [23, 26, 29, 32]  1    923520  models.yolo.Detect                      [155, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\n",
      "Model summary: 379 layers, 36164832 parameters, 36164832 gradients, 51.3 GFLOPs\n",
      "\n",
      "Transferred 627/627 items from hackaton_trafic_signs/yolov5m66/weights/last.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 1280\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA RTX A5000) 23.69G total, 0.41G reserved, 0.28G allocated, 23.00G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    36164832         205         1.820         61.91         30.59      (1, 3, 1280, 1280)                    list\n",
      "    36164832         410         3.244         39.62         35.59      (2, 3, 1280, 1280)                    list\n",
      "    36164832         820         6.094         46.72         54.35      (4, 3, 1280, 1280)                    list\n",
      "    36164832        1640        11.304         88.67         102.3      (8, 3, 1280, 1280)                    list\n",
      "    36164832        3280        22.110         174.5         192.8     (16, 3, 1280, 1280)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 13 for CUDA:0 18.76G/23.69G (79%) ‚úÖ\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 103 weight(decay=0.0), 107 weight(decay=0.0005078125), 107 bias\n",
      "Resuming training from hackaton_trafic_signs/yolov5m66/weights/last.pt from epoch 9 to 100 total epochs\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/jovyan/hack/train_annotation/labels.cache' images and lab\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/jovyan/hack/test_annotation/labels.cache' images and labels\u001b[0m\n",
      "Plotting labels to hackaton_trafic_signs/yolov5m66/labels.jpg... \n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mhackaton_trafic_signs/yolov5m66\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/99      21.5G    0.01947   0.005129    0.01413         22       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.799      0.535      0.575       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/99      22.5G    0.01945   0.005076    0.01356          8       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.817      0.535      0.589      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/99      22.5G    0.01945   0.005018    0.01289          9       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.836      0.539      0.606      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/99      22.5G    0.01915   0.005009     0.0123          4       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866        0.8      0.576      0.622      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/99      22.5G    0.01918   0.004977    0.01169         10       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.806      0.599      0.638      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/99      22.5G    0.01911   0.004939    0.01151         15       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.822        0.6      0.647      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/99      22.5G    0.01901   0.004963    0.01111         15       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.817      0.609      0.653      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/99      22.5G    0.01895    0.00492    0.01105          9       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.811      0.613      0.659      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/99      22.5G    0.01887   0.004975     0.0108         17       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.807      0.626      0.663      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/99      22.5G     0.0189   0.004971    0.01092         12       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.812      0.628       0.67       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/99      22.5G    0.01882   0.004869    0.01012         12       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.814      0.633      0.675      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/99      22.5G     0.0187   0.004912    0.01036         10       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.818      0.635       0.68       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/99      22.5G    0.01871   0.004887    0.01002         10       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.822      0.635      0.684      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/99      22.5G     0.0187   0.004857   0.009742         11       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.825      0.635       0.69       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/99      22.5G    0.01859   0.004877   0.009895          9       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.829      0.636      0.694      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/99      22.5G    0.01862   0.004822   0.009485         16       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.831      0.637      0.699      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/99      22.5G    0.01836   0.004845   0.009254         14       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.828      0.644      0.705       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/99      22.5G    0.01846    0.00485   0.009099          4       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.803      0.674      0.707      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/99      22.5G     0.0183   0.004749   0.008562         15       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.811      0.676      0.712      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/99      22.5G    0.01835   0.004747   0.008583         19       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.821      0.673      0.715       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/99      22.5G    0.01847   0.004796    0.00898         12       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866       0.82      0.681      0.717      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/99      22.5G    0.01815   0.004753   0.008533         10       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.821      0.682      0.721      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/99      22.5G    0.01827   0.004761   0.008656         25       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.823      0.683      0.726      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/99      22.5G    0.01805   0.004719   0.008446         11       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.822      0.687       0.73      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/99      22.5G    0.01806   0.004743     0.0085         14       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.826      0.684      0.736      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/99      22.5G    0.01799   0.004769    0.00853          3       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       5000       8866      0.821      0.691      0.744      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/99      22.5G    0.01822   0.004738   0.008302         36       1280:  ^C\n",
      "      35/99      22.5G    0.01822   0.004738   0.008302         36       1280:  \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/yolov5/train.py\", line 632, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/jovyan/yolov5/train.py\", line 526, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"/home/jovyan/yolov5/train.py\", line 332, in train\n",
      "    pbar.set_description(('%11s' * 2 + '%11.4g' * 5) %\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1280 --batch -1 --epochs 100 --data \"/home/jovyan/hack/trafic_signs.yaml\" --weights yolov5m6.pt --project \"hackaton_trafic_signs\" --name \"yolov5m6\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
